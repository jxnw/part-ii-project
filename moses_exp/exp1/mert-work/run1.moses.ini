# MERT optimized configuration
# decoder /home/jwang/github/mosesdecoder/bin/moses
# BLEU --not-estimated-- on dev /home/jwang/github/part-ii-project/corpus/dev/fce.dev.gold.bea19.or
# We were before running iteration 1
# finished Wed Oct 13 20:58:56 BST 2021
### MOSES CONFIG FILE ###
#########################

# input factors
[input-factors]
0

# mapping steps
[mapping]
0 T 0

[distortion-limit]
6

# feature functions
[feature]
UnknownWordPenalty
WordPenalty
PhrasePenalty
PhraseDictionaryMemory name=TranslationModel0 num-features=4 path=/home/jwang/github/part-ii-project/working/exp1/mert-work/filtered/phrase-table.0-0.1.1.gz input-factor=0 output-factor=0 
LexicalReordering name=LexicalReordering0 num-features=6 type=phrase-msd-bidirectional-fe-allff input-factor=0 output-factor=0 path=/home/jwang/github/part-ii-project/working/exp1/mert-work/filtered/reordering-table.phrase-msd-bidirectional-fe.0-0.1 
Distortion
KENLM name=LM0 factor=0 path=/home/jwang/lm/fce.train.gold.bea19.blm.co order=5

# dense weights for feature functions

[threads]
4
[weight]

LexicalReordering0= 0.300000 0.300000 0.300000 0.300000 0.300000 0.300000
Distortion0= 0.300000
LM0= 0.500000
WordPenalty0= -1.000000
PhrasePenalty0= 0.200000
TranslationModel0= 0.200000 0.200000 0.200000 0.200000
UnknownWordPenalty0= 1
